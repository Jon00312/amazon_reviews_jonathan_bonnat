import sys
import logging
import os
import torch
import boto3
import pandas as pd
from pathlib import Path
from transformers import pipeline
from datetime import datetime

# ----------------------------------------------------
# üì• Chargement Silver
# ----------------------------------------------------

def load_latest_silver_from_s3():
    s3 = boto3.client(
        "s3",
        aws_access_key_id=os.getenv("AWS_ACCESS_KEY_ID"),
        aws_secret_access_key=os.getenv("AWS_SECRET_ACCESS_KEY"),
        region_name=os.getenv("AWS_REGION")
    )

    bucket = os.getenv("S3_BUCKET")
    prefix = "cleaned/"

    objects = s3.list_objects_v2(Bucket=bucket, Prefix=prefix)
    files = [o["Key"] for o in objects.get("Contents", []) if o["Key"].endswith(".parquet")]

    if not files:
        raise RuntimeError("‚ùå Aucun fichier Silver trouv√© sur S3.")

    latest = sorted(files)[-1]
    return pd.read_parquet(f"s3://{bucket}/{latest}")


# ----------------------------------------------------
# üì• Run Zero Shot Job
# ----------------------------------------------------
def run_zero_shot_and_scoring_job():

    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s | %(levelname)s | %(message)s",
        handlers=[logging.StreamHandler(sys.stdout)],
        force=True
    )

    logger = logging.getLogger(__name__)
    logger.info("=== ZERO SHOT JOB (EXTERNE) ===")

    df = load_latest_silver_from_s3()
    if df.empty:
        raise RuntimeError("Dataset Silver vide")

    df["text_length"] = df["review_text"].str.len()

    device = 0 if torch.cuda.is_available() else -1


    classifier = pipeline(
        "zero-shot-classification",
        model="facebook/bart-large-mnli",
        device=device
    )

    candidate_labels = [
        "product quality",
        "product defect",
        "positive experience",
        "negative experience",
        "delivery issue",
        "delivery satisfaction",
        "price value",
    ]

    categories, confidences = [], []

    for text in df["review_text"].tolist():
        result = classifier(text, candidate_labels)
        categories.append(result["labels"][0])
        confidences.append(result["scores"][0])

    df["category"] = categories
    df["confidence_score"] = confidences

    output_path = Path("/shared") / f"classified_reviews_{datetime.now():%Y%m%d_%H%M%S}.parquet"
    df.to_parquet(output_path, index=False)

    logger.info(output_path)

    df["relevance_score"] = (
        0.40 * df["confidence_score"] +
        0.25 * (df["text_length"] / df["text_length"].max()) +
        0.15 * (abs(df["rating"] - 3) / 2) +
        df["has_image"].astype(int) * 0.05 +
        df["verified_buyer"].astype(int) * 0.05 +
        df["has_subscription"].astype(int) * 0.10
    )

    output_path = Path("/shared") / f"reviews_gold_{datetime.now():%Y%m%d_%H%M%S}.parquet"
    df.to_parquet(output_path, index=False)

if __name__ == "__main__":
    run_zero_shot_and_scoring_job()