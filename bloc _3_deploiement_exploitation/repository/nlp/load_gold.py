import os
import logging
import boto3
import pandas as pd
from pathlib import Path
from datetime import datetime
from dotenv import load_dotenv
from botocore.exceptions import ClientError, NoCredentialsError

# ----------------------------------------------------
# ‚öôÔ∏è CONFIGURATION
# ----------------------------------------------------

logger = logging.getLogger(__name__)
logger.info("=== [√âTAPE : LOAD GOLD ‚Üí S3] ===")

# ----------------------------------------------------
# üîê ENV
# ----------------------------------------------------
AWS_ACCESS_KEY_ID = os.getenv("AWS_ACCESS_KEY_ID")
AWS_SECRET_ACCESS_KEY = os.getenv("AWS_SECRET_ACCESS_KEY")
AWS_REGION = os.getenv("AWS_REGION")
S3_BUCKET = os.getenv("S3_BUCKET")


# ----------------------------------------------------
# üß± LOAD GOLD
# ----------------------------------------------------
def load_gold():
    """
    Charge la couche GOLD depuis le Data Lake local
    et l‚Äôupload vers S3 (curated/gold).
    """

    logger.info("üöÄ D√©marrage LOAD GOLD.")

    parquet_files = sorted(Path("/shared").glob("reviews_gold_*.parquet"))
    if not parquet_files:
        raise RuntimeError("‚ùå Aucun fichier GOLD trouv√©.")

    latest_parquet = parquet_files[-1]
    df_gold = pd.read_parquet(latest_parquet)

    if df_gold.empty:
        raise RuntimeError("‚ùå Fichier GOLD vide.")

    # ----------------------------------------------------
    # ‚òÅÔ∏è Upload S3
    # ----------------------------------------------------
    s3_uri = None
    try:
        s3_client = boto3.client(
            "s3",
            aws_access_key_id=AWS_ACCESS_KEY_ID,
            aws_secret_access_key=AWS_SECRET_ACCESS_KEY,
            region_name=AWS_REGION
        )

        s3_key = f"curated/{latest_parquet.name}"
        s3_client.upload_file(
            Filename=str(latest_parquet),
            Bucket=S3_BUCKET,
            Key=s3_key
        )

        s3_uri = f"s3://{S3_BUCKET}/{s3_key}"
        logger.info(f"üì§ GOLD upload√©e sur S3 : {s3_uri}")

    except (ClientError, NoCredentialsError) as e:
        logger.error(f"‚ùå Erreur upload GOLD S3 : {e}")
        raise

    # ----------------------------------------------------
    # üìä Audit
    # ----------------------------------------------------
    audit = {
        "timestamp": datetime.utcnow().isoformat(),
        "rows": len(df_gold),
        "columns": list(df_gold.columns),
        "file_name": latest_parquet.name,
        "file_size_MB": round(latest_parquet.stat().st_size / (1024 * 1024), 3),
        "avg_confidence_score": df_gold.get("confidence_score", pd.Series()).mean(),
        "avg_relevance_score": df_gold.get("relevance_score", pd.Series()).mean(),
        "s3_uri": s3_uri
    }

    audit_file = Path("/tmp") / f"audit_gold_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv"
    pd.DataFrame([audit]).to_csv(audit_file, index=False)

    logger.info(f"üìä Audit GOLD g√©n√©r√© : {audit_file}")
    logger.info("üèÜ LOAD GOLD termin√© avec succ√®s.")
