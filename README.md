# üß† Amazon Reviews ETL Pipeline

Ce projet impl√©mente un pipeline **ETL complet (Extract ‚Üí Transform ‚Üí Load)** permettant de traiter des avis Amazon √† partir d‚Äôune base transactionnelle PostgreSQL, de conserver une couche **Bronze rejouable**, de produire une couche **Silver propre et normalis√©e**, et de pr√©parer les donn√©es pour des usages analytiques et NLP.

Le pipeline s‚Äôappuie sur :
- **PostgreSQL** comme source transactionnelle
- **MongoDB** comme couche **Bronze** (donn√©es brutes historis√©es)
- **Amazon S3** comme **Data Lake** (couche Silver en Parquet)
- une couverture de tests unitaires
- une orchestration Python modulaire (pr√©par√©e pour Airflow)

---

# 1Ô∏è‚É£ Pr√©requis techniques

## Environnement requis
- Python ‚â• 3.10  
- PostgreSQL (local ou Docker)  
- MongoDB (local ou Docker)  
- AWS S3 (bucket + credentials IAM)

## Installation
```bash
pip install -r requirements.txt
```

---

## 2Ô∏è‚É£ Configuration (.env)

La configuration se fait via le fichier `config/.env`.

### PostgreSQL
- **DATABASE_CREATION_URI**
- **DATABASE_SERVER_URI**
- **NEW_DATABASE_NAME**

### AWS S3
- **AWS_ACCESS_KEY_ID**
- **AWS_SECRET_ACCESS_KEY**
- **AWS_REGION**
- **S3_BUCKET**

### MongoDB
- **MONGO_URI**
- **MONGO_DB_NAME**

---

# 3Ô∏è‚É£ Architecture du pipeline

## üü¶ EXTRACT
- Connexion √† PostgreSQL
- Extraction des tables :
  - buyer
  - subscription
  - product
  - orders
  - review
  - review_images
  - product_reviews
- G√©n√©ration d‚Äôun audit d‚Äôextraction
- Gestion propre des erreurs

Sortie : dictionnaire de DataFrames

---

## üü´ LOAD BRONZE ‚Üí MongoDB

- Donn√©es stock√©es **brutes**
- Une collection MongoDB par table source (`bronze_*`)
- Permet de rejouer tout le pipeline sans PostgreSQL

---

## üü™ TRANSFORM (Silver)

- Nettoyage du texte des avis
- Enrichissements :
  - product_id
  - has_image
  - has_subscription
  - verified_buyer
- Gestion explicite des rejets

Sorties :
- DataFrame Silver propre
- DataFrame des rejets

---

## üü© LOAD (Data Lake S3)

- Conversion en Parquet
- Upload vers :
  - cleaned/
  - rejects/
- G√©n√©ration d‚Äôun audit de chargement

---

# 4Ô∏è‚É£ Tests unitaires üß™

Outil : pytest

Couverture :
- extract : connexion DB, structure de sortie
- transform : nettoyage, enrichissements, rejets
- load : √©criture parquet
- load_mongodb : chargement bronze

Lancer les tests :
```bash
python -m pytest
```

R√©sultat attendu :
```
= 16 passed in <5s =
```

---

# 5Ô∏è‚É£ Commandes principales

Lancement de la cr√©ation BDD si besoin
```bash
python -m src.setup.create_database
```

Lancement global
```bash
python -m src.main
```

Lancement standalone
```bash
python -m src.etl.transform
python -m src.etl.extract
python -m src.etl.load_mongodb
python -m src.etl.transform
python -m src.etl.load
```

---

# 6Ô∏è‚É£ Dossiers g√©n√©r√©s

| Type | Destination |
|-----|------------|
| Bronze | MongoDB |
| Silver | S3 cleaned |
| Rejets | S3 rejects |
| Logs | logs/ |

---

# 7Ô∏è‚É£ Statut

‚úî Pipeline fonctionnel  
‚úî Tests valid√©s  
‚úî Architecture align√©e avec le sch√©ma pr√©sent√©  
üöÄ Pr√™t pour √©volutions NLP et orchestration
